{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8AB3SAIMvSENYWcGSZ7rT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muntasir2179/pytorch-learnig/blob/experiment-tracking/07_pytorch_experiment_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Experiment Tracking\n",
        "\n",
        "Machine Learning is very experimental.\n",
        "\n",
        "In order to figure out which experiments are worth persuing, that's where **experiment tracking** comes in, it helps us to figure out what doesn't work so we can know what does work.\n",
        "\n",
        "In this notebook, we are going to see an example of programmatically tracking experiments."
      ],
      "metadata": {
        "id": "OFlRC8asXXAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_L03Ie5YVIY",
        "outputId": "c4d478c2-699b-4e01-b8dc-6f95a008a544"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.1+cu121\n",
            "0.16.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhzOZszfZ9hF",
        "outputId": "f0c6d20a-349e-4243-b2af-629830076c57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4036, done.\u001b[K\n",
            "remote: Counting objects: 100% (1224/1224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (223/223), done.\u001b[K\n",
            "remote: Total 4036 (delta 1068), reused 1080 (delta 998), pack-reused 2812\u001b[K\n",
            "Receiving objects: 100% (4036/4036), 651.02 MiB | 16.29 MiB/s, done.\n",
            "Resolving deltas: 100% (2361/2361), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "\n",
        "# function for setting manual seed\n",
        "def set_seed():\n",
        "  torch.manual_seed(42)\n",
        "  torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4D2q8W7bSwe",
        "outputId": "d0f41e70-8ec9-41e5-8ea8-6cd89bb3881f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 Getting the data"
      ],
      "metadata": {
        "id": "DKrtEw_TcEj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "# example source: https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\n",
        "\n",
        "def download_data(source: str,\n",
        "                  destination: str,\n",
        "                  remove_source: bool = True) -> Path:\n",
        "  \"\"\"Downloads a zipped dataset from source and unzips to destinaiton.\"\"\"\n",
        "  # setup path to data folder\n",
        "  data_path = Path(\"data/\")\n",
        "  image_path = data_path / destination\n",
        "\n",
        "  # if the image folder doesn't exist, create it\n",
        "  if image_path.is_dir():\n",
        "    print(f\"[INFO] {image_path} directory already exists, skipping download.\")\n",
        "  else:\n",
        "    print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # download the target file\n",
        "    target_file = Path(source).name   # name of the file that the path contains\n",
        "    with open(data_path / target_file, \"wb\") as f:\n",
        "      request = requests.get(source)\n",
        "      print(f\"[INFO] Downloading {target_file} from {source}....\")\n",
        "      f.write(request.content)\n",
        "\n",
        "    # unzipping the target file\n",
        "    with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
        "      print(f\"[INFO] Unzipping {target_file} data...\")\n",
        "      zip_ref.extractall(image_path)\n",
        "\n",
        "    # remove .zip file if needed\n",
        "    if remove_source:\n",
        "      os.remove(data_path / target_file)\n",
        "\n",
        "    return image_path"
      ],
      "metadata": {
        "id": "b2pLBy8NcJBc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = download_data(source = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                           destination = \"pizza_steak_sushi\")\n",
        "image_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX6nqUoXflOV",
        "outputId": "80f7c9c8-3225-4156-85bc-0dffffb7b9c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip....\n",
            "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Create Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "pwZHq3BFhCYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Create DataLoaders with manual transforms\n",
        "\n",
        "The goal with transforms is to ensure custom data in formatted in a reproducible way as well as a way that will suit pretrained models."
      ],
      "metadata": {
        "id": "6MwB8rrAhJjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up the directories\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB6j8cIRhkEK",
        "outputId": "813da1c9-4969-4f9b-a59e-fe922af9a08f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up ImageNet normalization lavels\n",
        "# see hare: https://pytorch.org/vision/0.12/models.html\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# creating transform pipeline manually\n",
        "from torchvision import transforms\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n",
        "                                                                             test_dir = test_dir,\n",
        "                                                                             transform = manual_transforms,\n",
        "                                                                             batch_size = 32)\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DuV0V2bix-z",
        "outputId": "1508aff9-e3c3-4095-dcb9-fb58e0a0b2a3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7be96f4e52a0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7be96f4e41f0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}