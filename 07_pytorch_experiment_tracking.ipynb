{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMV2T8FP1b2d6sz4JpxteWO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muntasir2179/pytorch-learnig/blob/experiment-tracking/07_pytorch_experiment_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Experiment Tracking\n",
        "\n",
        "Machine Learning is very experimental.\n",
        "\n",
        "In order to figure out which experiments are worth persuing, that's where **experiment tracking** comes in, it helps us to figure out what doesn't work so we can know what does work.\n",
        "\n",
        "In this notebook, we are going to see an example of programmatically tracking experiments."
      ],
      "metadata": {
        "id": "OFlRC8asXXAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_L03Ie5YVIY",
        "outputId": "bbb0701c-b3c9-4411-f81d-8752c1d1bc1e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "0.16.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhzOZszfZ9hF",
        "outputId": "9d270226-aa37-45f2-ca93-e1d08eb28835"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4036, done.\u001b[K\n",
            "remote: Counting objects: 100% (1224/1224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (226/226), done.\u001b[K\n",
            "remote: Total 4036 (delta 1067), reused 1080 (delta 995), pack-reused 2812\u001b[K\n",
            "Receiving objects: 100% (4036/4036), 651.50 MiB | 39.73 MiB/s, done.\n",
            "Resolving deltas: 100% (2360/2360), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "\n",
        "# function for setting manual seed\n",
        "def set_seed():\n",
        "  torch.manual_seed(42)\n",
        "  torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4D2q8W7bSwe",
        "outputId": "2ae58fa4-aa46-43d0-9255-84a0c808995c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 Getting the data"
      ],
      "metadata": {
        "id": "DKrtEw_TcEj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "# example source: https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\n",
        "\n",
        "def download_data(source: str,\n",
        "                  destination: str,\n",
        "                  remove_source: bool = True) -> Path:\n",
        "  \"\"\"Downloads a zipped dataset from source and unzips to destinaiton.\"\"\"\n",
        "  # setup path to data folder\n",
        "  data_path = Path(\"data/\")\n",
        "  image_path = data_path / destination\n",
        "\n",
        "  # if the image folder doesn't exist, create it\n",
        "  if image_path.is_dir():\n",
        "    print(f\"[INFO] {image_path} directory already exists, skipping download.\")\n",
        "  else:\n",
        "    print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # download the target file\n",
        "    target_file = Path(source).name   # name of the file that the path contains\n",
        "    with open(data_path / target_file, \"wb\") as f:\n",
        "      request = requests.get(source)\n",
        "      print(f\"[INFO] Downloading {target_file} from {source}....\")\n",
        "      f.write(request.content)\n",
        "\n",
        "    # unzipping the target file\n",
        "    with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
        "      print(f\"[INFO] Unzipping {target_file} data...\")\n",
        "      zip_ref.extractall(image_path)\n",
        "\n",
        "    # remove .zip file if needed\n",
        "    if remove_source:\n",
        "      os.remove(data_path / target_file)\n",
        "\n",
        "    return image_path"
      ],
      "metadata": {
        "id": "b2pLBy8NcJBc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = download_data(source = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                           destination = \"pizza_steak_sushi\")\n",
        "image_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX6nqUoXflOV",
        "outputId": "1c8e4a2e-8bd3-43fe-a172-248d1bf20cf2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip....\n",
            "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Create Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "pwZHq3BFhCYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Create DataLoaders with manual transforms\n",
        "\n",
        "The goal with transforms is to ensure custom data in formatted in a reproducible way as well as a way that will suit pretrained models."
      ],
      "metadata": {
        "id": "6MwB8rrAhJjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up the directories\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB6j8cIRhkEK",
        "outputId": "b869c526-e769-41eb-b0e6-c7498d74b1c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up ImageNet normalization lavels\n",
        "# see hare: https://pytorch.org/vision/0.12/models.html\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# creating transform pipeline manually\n",
        "from torchvision import transforms\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n",
        "                                                                             test_dir = test_dir,\n",
        "                                                                             transform = manual_transforms,\n",
        "                                                                             batch_size = 32)\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DuV0V2bix-z",
        "outputId": "cd910be6-c142-4203-c25d-a9fa4866d007"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7b2557add2d0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7b2480bee1d0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Create DataLoaders using automatically created transforms\n",
        "\n",
        "The same principle applies for automatic transforms: we want our custom data in the same format as pretrained model was traind on."
      ],
      "metadata": {
        "id": "PWViy8Mnluza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up the directories\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "# loading weights of pretrained model\n",
        "# REGNET_Y_800MF - https://pytorch.org/vision/0.16/models/generated/torchvision.models.regnet_y_800mf.html#regnet-y-800mf\n",
        "weights = torchvision.models.RegNet_Y_800MF_Weights.DEFAULT  # DEFAULT - the best available weights\n",
        "automatic_transforms = weights.transforms()\n",
        "\n",
        "print(f\"Automatically created transforms: {automatic_transforms}\")\n",
        "\n",
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n",
        "                                                                             test_dir = test_dir,\n",
        "                                                                             transform = automatic_transforms,\n",
        "                                                                             batch_size = 32)\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ewbG6WomC8Q",
        "outputId": "39f0a3b5-295e-4e3b-bb18-c7ebe8c713f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created transforms: ImageClassification(\n",
            "    crop_size=[224]\n",
            "    resize_size=[232]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BILINEAR\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7b2557adcb50>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7b2480bede10>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.0 Getting a pretrained model, freeze the base layers and change the classifier head"
      ],
      "metadata": {
        "id": "aCWkR2FZi7l4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.regnet_y_800mf(weights = torchvision.models.RegNet_Y_800MF_Weights.DEFAULT)\n",
        "summary(model=model,\n",
        "        input_size= (1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEA5f_S4jFap",
        "outputId": "e514677b-8509-4eb8-d5e7-0d6bd95e9db6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "RegNet (RegNet)                                              [1, 3, 224, 224]     [1, 1000]            --                   True\n",
              "├─SimpleStemIN (stem)                                        [1, 3, 224, 224]     [1, 32, 112, 112]    --                   True\n",
              "│    └─Conv2d (0)                                            [1, 3, 224, 224]     [1, 32, 112, 112]    864                  True\n",
              "│    └─BatchNorm2d (1)                                       [1, 32, 112, 112]    [1, 32, 112, 112]    64                   True\n",
              "│    └─ReLU (2)                                              [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "├─Sequential (trunk_output)                                  [1, 32, 112, 112]    [1, 784, 7, 7]       --                   True\n",
              "│    └─AnyStage (block1)                                     [1, 32, 112, 112]    [1, 64, 56, 56]      --                   True\n",
              "│    │    └─ResBottleneckBlock (block1-0)                    [1, 32, 112, 112]    [1, 64, 56, 56]      19,016               True\n",
              "│    └─AnyStage (block2)                                     [1, 64, 56, 56]      [1, 144, 28, 28]     --                   True\n",
              "│    │    └─ResBottleneckBlock (block2-0)                    [1, 64, 56, 56]      [1, 144, 28, 28]     65,824               True\n",
              "│    │    └─ResBottleneckBlock (block2-1)                    [1, 144, 28, 28]     [1, 144, 28, 28]     73,620               True\n",
              "│    │    └─ResBottleneckBlock (block2-2)                    [1, 144, 28, 28]     [1, 144, 28, 28]     73,620               True\n",
              "│    └─AnyStage (block3)                                     [1, 144, 28, 28]     [1, 320, 14, 14]     --                   True\n",
              "│    │    └─ResBottleneckBlock (block3-0)                    [1, 144, 28, 28]     [1, 320, 14, 14]     266,596              True\n",
              "│    │    └─ResBottleneckBlock (block3-1)                    [1, 320, 14, 14]     [1, 320, 14, 14]     304,400              True\n",
              "│    │    └─ResBottleneckBlock (block3-2)                    [1, 320, 14, 14]     [1, 320, 14, 14]     304,400              True\n",
              "│    │    └─ResBottleneckBlock (block3-3)                    [1, 320, 14, 14]     [1, 320, 14, 14]     304,400              True\n",
              "│    │    └─ResBottleneckBlock (block3-4)                    [1, 320, 14, 14]     [1, 320, 14, 14]     304,400              True\n",
              "│    │    └─ResBottleneckBlock (block3-5)                    [1, 320, 14, 14]     [1, 320, 14, 14]     304,400              True\n",
              "│    │    └─ResBottleneckBlock (block3-6)                    [1, 320, 14, 14]     [1, 320, 14, 14]     304,400              True\n",
              "│    │    └─ResBottleneckBlock (block3-7)                    [1, 320, 14, 14]     [1, 320, 14, 14]     304,400              True\n",
              "│    └─AnyStage (block4)                                     [1, 320, 14, 14]     [1, 784, 7, 7]       --                   True\n",
              "│    │    └─ResBottleneckBlock (block4-0)                    [1, 320, 14, 14]     [1, 784, 7, 7]       1,361,888            True\n",
              "│    │    └─ResBottleneckBlock (block4-1)                    [1, 784, 7, 7]       [1, 784, 7, 7]       1,655,220            True\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 784, 7, 7]       [1, 784, 1, 1]       --                   --\n",
              "├─Linear (fc)                                                [1, 784]             [1, 1000]            785,000              True\n",
              "============================================================================================================================================\n",
              "Total params: 6,432,512\n",
              "Trainable params: 6,432,512\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 833.89\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 86.68\n",
              "Params size (MB): 25.73\n",
              "Estimated Total Size (MB): 113.01\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2byp4fVoi99",
        "outputId": "48a5438a-12d5-4e48-bce9-5daadac0cd39"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# freezing the feature layers\n",
        "for params in model.parameters():\n",
        "  params.requires_grad = False\n",
        "\n",
        "# configuring the classifier head\n",
        "features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features=features, out_features=len(class_names), bias=True)\n",
        "\n",
        "# make the last layer trainable\n",
        "model.fc.requires_grad_(requires_grad=True)\n",
        "\n",
        "# printing the model summary\n",
        "summary(model=model,\n",
        "        input_size= (1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTUwoO52muBO",
        "outputId": "44ed1419-452e-4240-ae74-66c4bb546ea9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "RegNet (RegNet)                                              [1, 3, 224, 224]     [1, 3]               --                   Partial\n",
              "├─SimpleStemIN (stem)                                        [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n",
              "│    └─Conv2d (0)                                            [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n",
              "│    └─BatchNorm2d (1)                                       [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n",
              "│    └─ReLU (2)                                              [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "├─Sequential (trunk_output)                                  [1, 32, 112, 112]    [1, 784, 7, 7]       --                   False\n",
              "│    └─AnyStage (block1)                                     [1, 32, 112, 112]    [1, 64, 56, 56]      --                   False\n",
              "│    │    └─ResBottleneckBlock (block1-0)                    [1, 32, 112, 112]    [1, 64, 56, 56]      (19,016)             False\n",
              "│    └─AnyStage (block2)                                     [1, 64, 56, 56]      [1, 144, 28, 28]     --                   False\n",
              "│    │    └─ResBottleneckBlock (block2-0)                    [1, 64, 56, 56]      [1, 144, 28, 28]     (65,824)             False\n",
              "│    │    └─ResBottleneckBlock (block2-1)                    [1, 144, 28, 28]     [1, 144, 28, 28]     (73,620)             False\n",
              "│    │    └─ResBottleneckBlock (block2-2)                    [1, 144, 28, 28]     [1, 144, 28, 28]     (73,620)             False\n",
              "│    └─AnyStage (block3)                                     [1, 144, 28, 28]     [1, 320, 14, 14]     --                   False\n",
              "│    │    └─ResBottleneckBlock (block3-0)                    [1, 144, 28, 28]     [1, 320, 14, 14]     (266,596)            False\n",
              "│    │    └─ResBottleneckBlock (block3-1)                    [1, 320, 14, 14]     [1, 320, 14, 14]     (304,400)            False\n",
              "│    │    └─ResBottleneckBlock (block3-2)                    [1, 320, 14, 14]     [1, 320, 14, 14]     (304,400)            False\n",
              "│    │    └─ResBottleneckBlock (block3-3)                    [1, 320, 14, 14]     [1, 320, 14, 14]     (304,400)            False\n",
              "│    │    └─ResBottleneckBlock (block3-4)                    [1, 320, 14, 14]     [1, 320, 14, 14]     (304,400)            False\n",
              "│    │    └─ResBottleneckBlock (block3-5)                    [1, 320, 14, 14]     [1, 320, 14, 14]     (304,400)            False\n",
              "│    │    └─ResBottleneckBlock (block3-6)                    [1, 320, 14, 14]     [1, 320, 14, 14]     (304,400)            False\n",
              "│    │    └─ResBottleneckBlock (block3-7)                    [1, 320, 14, 14]     [1, 320, 14, 14]     (304,400)            False\n",
              "│    └─AnyStage (block4)                                     [1, 320, 14, 14]     [1, 784, 7, 7]       --                   False\n",
              "│    │    └─ResBottleneckBlock (block4-0)                    [1, 320, 14, 14]     [1, 784, 7, 7]       (1,361,888)          False\n",
              "│    │    └─ResBottleneckBlock (block4-1)                    [1, 784, 7, 7]       [1, 784, 7, 7]       (1,655,220)          False\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 784, 7, 7]       [1, 784, 1, 1]       --                   --\n",
              "├─Linear (fc)                                                [1, 784]             [1, 3]               2,355                True\n",
              "============================================================================================================================================\n",
              "Total params: 5,649,867\n",
              "Trainable params: 2,355\n",
              "Non-trainable params: 5,647,512\n",
              "Total mult-adds (M): 833.11\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 86.67\n",
              "Params size (MB): 22.60\n",
              "Estimated Total Size (MB): 109.88\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}