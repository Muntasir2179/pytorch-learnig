{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLt7xO7uLOy+F7uamrapmL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fd4071d2fa64e9e8189f168c62c78ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_454d9041a72a48da87218e59c7bcb4dd",
              "IPY_MODEL_fc5c5b8511944dce93b2ceb4e39b43a2",
              "IPY_MODEL_e2ec25b1f179471eb617119d26a43e49"
            ],
            "layout": "IPY_MODEL_b0738c29e5dd40af8a85ab35e4889b8b"
          }
        },
        "454d9041a72a48da87218e59c7bcb4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c92d5db0cad14bbfaf75cba9d5401a0a",
            "placeholder": "​",
            "style": "IPY_MODEL_176a4fce06224d20b18c8e502cdacefc",
            "value": "100%"
          }
        },
        "fc5c5b8511944dce93b2ceb4e39b43a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6144e231b85a4e72b555e5cb8c4b48aa",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7efc96df365a4bb0bd613e9d7419489f",
            "value": 6
          }
        },
        "e2ec25b1f179471eb617119d26a43e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10c38bf139244be9b6fc532be887b2af",
            "placeholder": "​",
            "style": "IPY_MODEL_86683e58973e46eaa77381c4ae6eb97a",
            "value": " 6/6 [00:17&lt;00:00,  2.99s/it]"
          }
        },
        "b0738c29e5dd40af8a85ab35e4889b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c92d5db0cad14bbfaf75cba9d5401a0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "176a4fce06224d20b18c8e502cdacefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6144e231b85a4e72b555e5cb8c4b48aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efc96df365a4bb0bd613e9d7419489f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10c38bf139244be9b6fc532be887b2af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86683e58973e46eaa77381c4ae6eb97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muntasir2179/pytorch-learnig/blob/transfer-learning/06_pytorch_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch transfer learning\n",
        "\n",
        "What is transfer learning?\n",
        "Transfer learning involves taking the parameters of what one model has learned on another dataset and applying to our own problem.\n",
        "\n",
        "* Pretrained model = foundation models"
      ],
      "metadata": {
        "id": "E2augz39isiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy535YY0ip7a",
        "outputId": "d4a32ba2-c8fd-4f18-cc16-8720f9961764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "0.16.0+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__) # want 1.12+\n",
        "print(torchvision.__version__) # want 0.13+"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWprdRWxxgQh",
        "outputId": "9949b279-c52c-4ef6-8c08-0845d28395d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4036, done.\u001b[K\n",
            "remote: Counting objects: 100% (1224/1224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
            "remote: Total 4036 (delta 1068), reused 1078 (delta 996), pack-reused 2812\u001b[K\n",
            "Receiving objects: 100% (4036/4036), 651.02 MiB | 16.46 MiB/s, done.\n",
            "Resolving deltas: 100% (2361/2361), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pveA6ISxzMzp",
        "outputId": "e5ab7dad-474e-40f9-fa9a-67b40b5bb38a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6caF5E8yzasY",
        "outputId": "783ecc63-1d20-41e6-bb18-e535d7631d9c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec  3 16:32:11 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 Get the data\n",
        "\n",
        "We need our pizza, steak and sushi data to build a transfer learning model on."
      ],
      "metadata": {
        "id": "2ziXksSgz30f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "# setting up the data paths\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists, skepping re-download.\")\n",
        "else:\n",
        "  print(f\"Did not find {image_path}, downloading it...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # download data\n",
        "  with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as file:\n",
        "    request = requests.get(url=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading pizza_steak_sushi data...\")\n",
        "    file.write(request.content)\n",
        "\n",
        "  # unzip the data\n",
        "  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "  # removing the pizza_steak_sushi.zip file\n",
        "  os.remove(data_path / \"pizza_steak_sushi.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9rQ2V-cz7uI",
        "outputId": "a4106e2d-7a40-45d2-b41f-9b78d1968418"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/pizza_steak_sushi, downloading it...\n",
            "Downloading pizza_steak_sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up the directory paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQJ7RHwQ7g4O",
        "outputId": "580e8c13-fa25-4fda-cece-347db70bbc28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Create Datasets and DataLoaders\n",
        "\n",
        "We are going to use `data_setup.py` and `create_dataloaders()` function that we have written in `Going Modular` section.\n",
        "\n",
        "There's one thing we have to think about when loading: how to **transform** it?\n",
        "Ans with `torchvision` there's two ways to do this:\n",
        "\n",
        "1. Manually created transforms - What transforms we want our data to go through.\n",
        "2. Automatically created transforms - The transforms that is defined for the model that we want to use.\n",
        "\n",
        "Important point: When using a pretrained model, it's important that the data (including the custom data) that you pass through it is **transformed** in the same way that the data the model was trained on."
      ],
      "metadata": {
        "id": "-r0U3EbT8J41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup"
      ],
      "metadata": {
        "id": "dw56N0Pm8nv2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Createing a transform for `torchvision.models` (manual creation)\n",
        "\n",
        "`torchvision.models` contains pretrained models (models ready for transfer learning) right within `torchvision`.\n",
        "\n",
        "While using transfer learning, we need to keep the data distribution same as the data which is used to train the pretrained model that we want to use.\n",
        "\n",
        ">All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. You can use the following transform to normalize:\n",
        "\n",
        "```python\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "```"
      ],
      "metadata": {
        "id": "ujZHoKeH_ry9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),  # resizing the image into (224, 224)\n",
        "    transforms.ToTensor(),  # getting the values between (1, 0)\n",
        "    normalize  # make sure images have the same distribution as ImageNet (where our pretrained model has been trained)\n",
        "])"
      ],
      "metadata": {
        "id": "mAaQOIPI_7W0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "tran_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n",
        "                                                                              test_dir = test_dir,\n",
        "                                                                              transform = manual_transforms,\n",
        "                                                                              batch_size = 32)\n",
        "tran_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxZsnJOwGQ_C",
        "outputId": "6361c993-bc25-45d4-b6d4-46ab9631c4a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x78ee0e2b1240>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x78ee0e2b1ff0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Creating a transform for `torchvision.models` (auto creation)\n",
        "\n",
        "As of `torchvision` v0.13+ there is now support for automatic data transform creation based on the pretrained model weights we are using."
      ],
      "metadata": {
        "id": "NQeUUGn8HgQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.RegNet_X_3_2GF_Weights.DEFAULT # DEFAULT = best available weights\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40rJROORHf2F",
        "outputId": "2d7ce5e6-7189-4eb5-ff42-d5edb8ccc880"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RegNet_X_3_2GF_Weights.IMAGENET1K_V2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the transfoms used to create our pretrained weights\n",
        "auto_transforms = weights.transforms()\n",
        "auto_transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4euRnXrJ2vy",
        "outputId": "50fa98d5-e9be-4e6e-e34e-8b92b140c7c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[232]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating DataLoaders using automatic transforms\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n",
        "                                                                               test_dir = test_dir,\n",
        "                                                                               transform = auto_transforms,\n",
        "                                                                               batch_size = 32)\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWnpVYU2KW8y",
        "outputId": "c25747e3-28bf-4fb7-a1d8-2da5f41c1d0c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x78ee0e2b2f80>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x78ee0e2b1c00>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.0 Getting a pretrained model\n",
        "\n",
        "There are various places to get pretrained models, such as:\n",
        "1. PyTorch domain libraries.\n",
        "2. Libraries like `timm` (torch image models)\n",
        "3. HuggingFace Hub (for plenty different models)\n",
        "4. Paperswithcode (for models across different problem space/domains)"
      ],
      "metadata": {
        "id": "ermq9QUmq6vD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Which pretrained model should we use?\n",
        "\n",
        "*Experiment, experiment, experiment*\n",
        "\n",
        "The whole idea of transfer learning: take an already well-performing model from a problem space similar to your own and then customize to our own problem.\n",
        "\n",
        "There are three things to consider:\n",
        "1. Speed - How fast does it run.\n",
        "2. Size - How big the model is?\n",
        "3. Performance - How well does it go on our choosen problem (e.g. how well does it classify food images? for FoodVision Mini)?\n",
        "\n",
        "Where does the model live?\n",
        "\n",
        "Is it on device? (Like a self-driving car)\n",
        "\n",
        "Or does it live on a server?\n",
        "\n",
        "Looking at https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights\n",
        "\n",
        "Which model should we choose?\n",
        "\n",
        "For our case (deploying FoodVision Mini on a mobile device), it looks like REGNET_X_3_2GF is one of our best options in terms of performance vs size.\n",
        "\n",
        "However, in light of The Bitter Lesson, if we had infinite compute, we'd likely pick the bigest model + most parameters + most general we could - http://www.incompleteideas.net/IncIdeas/BitterLesson.html"
      ],
      "metadata": {
        "id": "7hm5Ka3arsbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Setting up a pretrained model\n",
        "\n",
        "We want to create an instance of REGNET_X_3_2GF - https://pytorch.org/vision/stable/models/generated/torchvision.models.regnet_x_3_2gf.html#torchvision.models.RegNet_X_3_2GF_Weights"
      ],
      "metadata": {
        "id": "_mdO6sdlziY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# old method of creating a pretrained model (prior to torchvision v0.13)\n",
        "# model = torchvision.models.regnet_x_3_2gf(pretrained=True)\n",
        "# model\n",
        "\n",
        "# new method of creating a pretrained model (torchvision v0.13+)\n",
        "weights = torchvision.models.RegNet_X_3_2GF_Weights.DEFAULT\n",
        "model = torchvision.models.regnet_x_3_2gf(weights = weights).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joe7GYMnz71H",
        "outputId": "a2abd04e-df44-4441-feff-6c25c09727c0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RegNet(\n",
              "  (stem): SimpleStemIN(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (trunk_output): Sequential(\n",
              "    (block1): AnyStage(\n",
              "      (block1-0): ResBottleneckBlock(\n",
              "        (proj): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block1-1): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (block2): AnyStage(\n",
              "      (block2-0): ResBottleneckBlock(\n",
              "        (proj): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block2-1): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block2-2): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block2-3): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block2-4): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block2-5): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (block3): AnyStage(\n",
              "      (block3-0): ResBottleneckBlock(\n",
              "        (proj): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 432, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-1): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-2): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-3): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-4): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-5): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-6): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-7): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-8): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-9): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-10): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-11): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-12): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-13): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-14): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (block4): AnyStage(\n",
              "      (block4-0): ResBottleneckBlock(\n",
              "        (proj): Conv2dNormActivation(\n",
              "          (0): Conv2d(432, 1008, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(432, 1008, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(1008, 1008, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=21, bias=False)\n",
              "            (1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(1008, 1008, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block4-1): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(1008, 1008, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(1008, 1008, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=21, bias=False)\n",
              "            (1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(1008, 1008, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=1008, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check how many hidden units are there in the fully connected layer\n",
        "# it looks like the model is trained for 1000 image classes\n",
        "model.fc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFsvKdiqBRhC",
        "outputId": "bdca911a-bf35-4e23-9fac-5cca6c7fab88"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1008, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Freezing the base model and changing the output layer to suit our needs\n",
        "\n",
        "With a feature extractor model, typically we will \"freeze\" the base layers of a pretrained/foundation model and update the output layer to suit our own problem."
      ],
      "metadata": {
        "id": "gk0tH8OqjZ1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# freezing the feature extractor layers / base layers\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False   # turning off the gradient tracking for learned parameters"
      ],
      "metadata": {
        "id": "EomguGkBEHQf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "num_features = model.fc.in_features  # getting the feature vector size\n",
        "model.fc = nn.Linear(in_features=num_features,  # feature commig in\n",
        "                     out_features=len(class_names)).to(device)  # updating the last layer for custom dataset\n",
        "\n",
        "# making the last layer trainable\n",
        "model.fc.requires_grad_(requires_grad=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEyUbE3SFObY",
        "outputId": "063a4e2a-651b-4684-80c0-8fd1721fd732"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1008, out_features=3, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.0 Training the model"
      ],
      "metadata": {
        "id": "qQ35CbmTnucK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the loss function and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "9tjsoeqanyK1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing train functions\n",
        "from going_modular.going_modular import engine\n",
        "\n",
        "# set manual seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# training the model\n",
        "results = engine.train(model = model,\n",
        "                       train_dataloader = train_dataloader,\n",
        "                       test_dataloader = test_dataloader,\n",
        "                       loss_fn = loss_fn,\n",
        "                       optimizer = optimizer,\n",
        "                       device = device,\n",
        "                       epochs = 6)\n",
        "\n",
        "# end time\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Total training time: {end_time - start_time: 0.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178,
          "referenced_widgets": [
            "0fd4071d2fa64e9e8189f168c62c78ca",
            "454d9041a72a48da87218e59c7bcb4dd",
            "fc5c5b8511944dce93b2ceb4e39b43a2",
            "e2ec25b1f179471eb617119d26a43e49",
            "b0738c29e5dd40af8a85ab35e4889b8b",
            "c92d5db0cad14bbfaf75cba9d5401a0a",
            "176a4fce06224d20b18c8e502cdacefc",
            "6144e231b85a4e72b555e5cb8c4b48aa",
            "7efc96df365a4bb0bd613e9d7419489f",
            "10c38bf139244be9b6fc532be887b2af",
            "86683e58973e46eaa77381c4ae6eb97a"
          ]
        },
        "id": "NG8eehqqoC8T",
        "outputId": "10190b14-bf68-4c43-b6b2-baf126506ec6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fd4071d2fa64e9e8189f168c62c78ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 1.0828 | train_acc: 0.4727 | test_loss: 1.0738 | test_acc: 0.4261\n",
            "Epoch: 2 | train_loss: 0.9492 | train_acc: 0.5938 | test_loss: 0.9518 | test_acc: 0.6913\n",
            "Epoch: 3 | train_loss: 0.7999 | train_acc: 0.8164 | test_loss: 0.8647 | test_acc: 0.7633\n",
            "Epoch: 4 | train_loss: 0.7115 | train_acc: 0.7656 | test_loss: 0.7876 | test_acc: 0.8248\n",
            "Epoch: 5 | train_loss: 0.6756 | train_acc: 0.7812 | test_loss: 0.7495 | test_acc: 0.7936\n",
            "Epoch: 6 | train_loss: 0.6449 | train_acc: 0.7656 | test_loss: 0.7074 | test_acc: 0.8864\n",
            "Total training time:  17.722\n"
          ]
        }
      ]
    }
  ]
}